# 计算机网络篇


---

## URL分解
<http://www.baidu.com>
url => 统一资源定位符，网址，是IP的一个映射
https => 协议 (http和TCP之间加了 TSL或SLL 层)
www => 服务器
baidu.com => 域名

---
## HTTP / HTTPS

### http 和 https 的基本概念
**http**: 是一个客户端和服务器端请求和应答的标准（TCP），用于从 WWW 服务器传输超文本到本地浏览器的超文本传输协议。
**https**:是以安全为目标的 HTTP 通道，即 HTTP 下 加入 SSL 层进行加密。其作用是：建立一个信息安全通道，来确保数据的传输，确保网站的真实性。

### [HTTP协议头](https://segmentfault.com/a/1190000018234763)
General Header (通用头 (请求响应都会有) )
Request Header (请求头)
Response Header (响应头)
Entity Header (实体头 (针对body体) )
![一个完成http头](https://segmentfault.com/img/bVboJHX)

### General Header 通用头
![通用头](https://segmentfault.com/img/bVboBwP)
Cache-Control——控制缓存的行为
Connection(禁止修改)——决定当前的事务完成后，是否会关闭网络连接
Date——创建报文的日期时间
Keep-Alive——用来设置超时时长和最大请求数
Via(禁止修改)——这个消息首部可以用来追踪消息转发情况，防止循环请求，以及识别在请求或响应传递链中消息发送者对于协议的支持能力。
Warning——错误通知
Trailer——允许发送方在分块发送的消息后面添加额外的元信息
Upgrade——升级为其他协议

### Request Header 请求头
![请求头](https://segmentfault.com/img/bVboBxd)
Accept——客户端可以处理的内容类型；并使用 Content-Type 应答头通知客户端它的选择详情
Accept-Encoding(禁止修改)——客户端能够理解的内容编码方式(gzip|br|deflate)
Accept-Language(禁止修改)——客户端可以理解的自然语言
Authorization——含有服务器用于验证用户代理身份的凭证，通常会在服务器返回401 Unauthorized 状态码以及WWW-Authenticate 消息头之后在后续请求中发送此消息头
Cookie——通过Set-Cookie设置的值
DNT——表明用户对于网站追踪的偏好
From——用户的电子邮箱地址
Host(禁止修改)——请求资源所在服务器
If-Match——比较实体标记（ETag）
If-Modified-Since——比较资源的更新时间
If-None-Match——比较实体标记（与 If-Match 相反）
If-Range——资源未更新时发送实体 Byte 的范围请求
If-Unmodified-Since——比较资源的更新时间（与 If-Modified-Since 相反）
Origin(禁止修改)——表明了请求来自于哪个站点；详情
Proxy-Authorization——代理服务器要求客户端的认证信息
Range——告知服务器返回文件的哪一部分。在一个 Range 首部中，可以一次性请求多个部分，服务器会以 multipart 文件的形式将其返回
Referer(禁止修改)——包含了当前请求页面的来源页面的地址，即表示当前页面是通过此来源页面里的链接进入的
Sec-fetch-*(禁止修改) ——获取元数据标头指示请求的目的地，即如何使用获取的数据。
Upgrade-Insecure-Requests——表示客户端优先选择加密及带有身份验证的响应
User-Agent——浏览器信息

### Response Header 响应头
![响应头](https://segmentfault.com/img/bVboBwW)
Access-Control-*——响应头用于在请求跨域时的处理。
Accept-Ranges——是否接受字节范围请求
Age——消息对象在缓存代理中存贮的时长，以秒为单位
Content-Disposition——回复的内容该以何种形式展示，是以内联的形式（预览），还是以附件的形式下载并保存到本地。(inline|attachment)
Content-Security-Policy——允许站点管理者在指定的页面控制用户代理的资源
ETag——缓存未更改的资源；链接描述
Expires——包含日期/时间， 即在此时候之后，响应过期
Last-Modified——其中包含源头服务器认定的资源做出修改的日期及时间。 它通常被用作一个验证器来判断接收到的或者存储的资源是否彼此一致
Location——令客户端重定向至指定 URI
Proxy-Authenticate——代理服务器对客户端的认证信息
Public-Key-Pins——包含该Web 服务器用来进行加密的 public key （公钥）信息
Public-Key-Pins-Report-Only——设置在公钥固定不匹配时，发送错误信息到report-uri
Referrer-Policy——用来监管哪些访问来源信息——会在 Referer 中发送
Retry-After——表示用户代理需要等待多长时间之后才能继续发送请求
Server——首部包含了处理请求的源头服务器所用到的软件相关信息。
Set-Cookie——服务器端向客户端发送 cookie
SourceMap——HTTP 响应头链接生成的代码到一个 source map，使浏览器能够重建原始的资源然后显示在调试器里。
Strict-Transport-Security——它告诉浏览器只能通过HTTPS访问当前资源
Timing-Allow-Origin——用于指定特定站点，以允许其访问Resource Timing API提供的相关信息
Transfer-Encoding(禁止修改)——传递给用户所采用的编码形式（gzip|deflate）
Vary——它决定了对于未来的一个请求头，应该用一个缓存的回复 (response) 还是向源服务器请求一个新的回复
WWW-Authenticate——定义了使用何种验证方式去获取对资源的连接
X-XSS-Protection——当检测到跨站脚本攻击 (XSS)时，浏览器将停止加载页面

### Entity Header 实体头 / 请求参数
![实体头](https://segmentfault.com/img/bVboBxy)
Allow——枚举资源所支持的 HTTP 方法的集合（GET, POST, HEAD）；详情
Content-Encoding——用于对特定媒体类型的数据进行压缩(gzip|br|deflate)；详情
Content-Language——访问者希望采用的语言或语言组合（需配合html lang="de"）；详情
Content-Length(禁止修改)——发送给接收方的消息主体的大小；详情
Content-Location——替代对应资源的 URI；详情
Content-Range——实体主体的位置范围；详情
Content-Security-Policy——允许站点管理者控制用户代理能够为指定的页面加载哪些资源，这将帮助防止跨站脚本攻击
Content-Type——客户端告诉服务器实际发送的数据类型,服务端告诉客户端返回的内容类型（text/html; charset=utf-8）；详情

### [HTTP状态码](https://www.runoob.com/http/http-status-codes.html)
|分类|分类描述|
|---|---|
|1**|信息，服务器收到请求，需要请求者继续执行操作|
|2**|成功，操作被成功接收并处理|
|3**|重定向，需要进一步的操作以完成请求|
|4**|客户端错误，请求包含语法错误或无法完成请求|
|5**|服务器错误，服务器在处理请求的过程中发生了错误|

### [性能优化为什么要减少 HTTP 访问次数？](https://blog.csdn.net/chenchun91/article/details/52207008)
每次请求都会产生连接开销（域名解析 > tcp链接 > 发送请求 > 等待(网络延迟和服务器处理时间) > 下载资源 > 文件解析）

### Http请求的过程与原理 || 从输入URL到页面加载的全过程
1. 首先在浏览器中输入URL
2. 查找缓存：浏览器先查看浏览器缓存-系统缓存-路由缓存-ISP缓存中是否有该地址页面，如果有则显示页面内容。如果没有则进行下一步。
   - 浏览器缓存：浏览器会记录DNS一段时间，因此，只是第一次访问时解析DNS请求；
   - 操作系统缓存:如果在浏览器缓存中不包含这个记录，则会使系统调用操作系统， 获取操作系统的记录(保存最近的DNS查询缓存)；
   - 路由器缓存：如果上述两个步骤均不能成功获取DNS记录，继续搜索路由器缓存；
   - ISP缓存：若上述均失败，继续向ISP搜索。(ISP缓存，本身是一种宽带接入提供商给网页批量访问加速的技术。ISP会将当前访问量较大的网页内容放到ISP服务器的缓存中，当有新的用户请求相同内容时，可以直接从缓存中发送相关信息，不必每次都去访问真正的网站，从而加快了不同用户对相同内容的访问速度，同时也能节省网间流量结算成本。ISP缓存主要以缓存静态页面为主，比如新浪的新闻页。如果ISP的缓存中的网页带有用户SESSIONID信息，就可能发生登录串号现象。当用户A登录时服务端返回页面内容被ISP缓存，这时同网络的用户B访问该网站，直接取得了刚才ISP缓存的信息，而该缓存信息中包含有用户A的SESSIONID（此时用户A还未退出），这样用户B处就显示出了A的信息。)
3. DNS域名解析：浏览器向DNS服务器发起请求，解析该URL中的域名对应的IP地址。DNS服务器是基于UDP的，因此会用到UDP协议。
4. 建立TCP连接：解析出IP地址后，根据IP地址和默认80端口，和服务器建立TCP连接
5. 发起HTTP请求：浏览器发起读取文件的HTTP请求，该请求报文作为TCP三次握手的第三次数据发送给服务器
6. 服务器响应请求并返回结果：服务器对浏览器请求做出响应，并把对应的html文件发送给浏览器
7. 关闭TCP连接：通过四次挥手释放TCP连接
8. 浏览器渲染：客户端（浏览器）解析HTML内容并渲染出来，浏览器接收到数据包后的解析流程为：
   - 构建DOM树：词法分析然后解析成DOM树（dom tree），是由dom元素及属性节点组成，树的根是document对象
   - 构建CSS规则树：生成CSS规则树（CSS Rule Tree）
   - 构建render树：Web浏览器将DOM和CSSOM结合，并构建出渲染树（render tree）
   - 布局（Layout）：计算出每个节点在屏幕中的位置
   - 绘制（Painting）：即遍历render树，并使用UI后端层绘制每个节点。
9. JS引擎解析过程：调用JS引擎执行JS代码（JS的解释阶段，预处理阶段，执行阶段生成执行上下文，VO，作用域链、回收机制等等）
   - 创建window对象：window对象也叫全局执行环境，当页面产生时就被创建，所有的全局变量和函数都属于window的属性和方法，而DOM Tree也会映射在window的doucment对象上。当关闭网页或者关闭浏览器时，全局执行环境会被销毁。
   - 加载文件：完成js引擎分析它的语法与词法是否合法，如果合法进入预编译
   - 预编译：在预编译的过程中，浏览器会寻找全局变量声明，把它作为window的属性加入到window对象中，并给变量赋值为'undefined'；寻找全局函数声明，把它作为window的方法加入到window对象中，并将函数体赋值给他（匿名函数是不参与预编译的，因为它是变量）。而变量提升作为不合理的地方在ES6中已经解决了，函数提升还存在。
   - 解释执行：执行到变量就赋值，如果变量没有被定义，也就没有被预编译直接赋值，在ES5非严格模式下这个变量会成为window的一个属性，也就是成为全局变量。string、int这样的值就是直接把值放在变量的存储空间里，object对象就是把指针指向变量的存储空间。函数执行，就将函数的环境推入一个环境的栈中，执行完成后再弹出，控制权交还给之前的环境。JS作用域其实就是这样的执行流机制实现的。

### http 和 https 的区别及优缺点？
1. http 是超文本传输协议，信息是明文传输，https 协议要比 http 协议安全，https 是具有安全性的 ssl 加密传输协议，可防止数据在传输过程中被窃取、改变，确保数据的完整性(当然这种安全性并非绝对的，对于更深入的 Web 安全问题，此处暂且不表)。
2. http 协议的默认端口为 80，https 的默认端口为 443。
3. http 的连接很简单，是无状态的。https 握手阶段比较费时，会使页面加载时间延长 50%，增加 10%~20%的耗电。
4. https 缓存不如 http 高效，会增加数据开销。
5. https 协议需要 ca 证书，费用较高，功能越强大的证书费用越高。
6. SSL 证书需要绑定 IP，不能再同一个 IP 上绑定多个域名，IPV4 资源支持不了这种消耗。

### [http/1.0 http/1.1 http/2 与 http/3 的区别？](https://zhuanlan.zhihu.com/p/266578819)
**HTTP 1.0**：
无状态（无法记录过去的请求），无连接（单次tcp响应后即刻断开）
短连接：每次发送请求都要重新建立tcp请求，即三次握手，非常浪费性能
队头阻塞
无host头域，也就是http请求头里的host
不允许断点续传，而且不能只传输对象的一部分，要求传输整个对象

**HTTP 1.1**：
长连接，流水线（假并行，仍旧存在对头阻塞），使用connection:keep-alive使用长连接
请求管道化。但长连接会给服务器造成压力
增加缓存处理（新的字段如cache-control）
增加Host字段，支持断点传输等

[HTTP 2.0](https://juejin.cn/post/6844903796225785870)：
**二进制分帧**：通过在应用层和传输层之间增加一个二进制分层帧，突破了HTTP1.1的性能限制，改进传输性能
**头部压缩**：双方各自维护一个header的索引表，使得不需要直接发送值，通过发送key缩减头部大小
**多路复用**：（或连接共享），使用多个stream，每个stream又分帧传输，使得一个tcp连接能够处理多个http请求
**服务器推送**：（Sever push）

**HTTP 3.0**：
基于google的QUIC协议，而quic协议是使用udp实现的
减少了tcp三次握手时间，以及tls握手时间
解决了http 2.0中前一个stream丢包导致后一个stream被阻塞的问题
优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗
连接迁移，不再用tcp四元组确定一个连接，而是用一个64位随机数来确定这个连接
更合适的流量控制
基于UDP实现
0RTT建连
基于UDP的多路复用
加密认证的报文
向前纠错机制

---
## [DNS](https://blog.csdn.net/baidu_37964071/article/details/80500825)
DNS：（Domain Name System 域名解析协议），DNS协议是用来将域名转换为IP地址（也可以将IP地址转换为相应的域名地址）。
我们都知道，TCP/IP中使用的是IP地址和端口号来确定网络上某一台主机上的某一个程序，不免有人有疑问，为什么不用域名来直接进行通信呢？
1. 因为IP地址是固定长度的，IPv4是32位，IPv6是128位，而域名是变长的，不便于计算机处理。
2. IP地址对于用户来说不方便记忆，但域名便于用户使用，例如www.baidu.com这是百度的域名。

总结一点就是IP地址是面向主机的，而域名则是面向用户的。
**hosts文件**：域名和IP的对应关系保存在一个叫hosts文件中。
最初，通过互联网信息中心来管理这个文件，如果有一个新的计算机想接入网络，或者某个计算IP变更都需要到信息中心申请变更hosts文件。其他计算机也需要定期更新，才能上网。
但是这样太麻烦了，就出现了DNS系统。

**DNS系统**
一个组织的系统管理机构, 维护系统内的每个主机的IP和主机名的对应关系
如果新计算机接入网络，将这个信息注册到数据库中
用户输入域名的时候，会自动查询DNS服务器，由DNS服务器检索数据库，得到对应的IP地址
我们可以通过命令查看自己的hosts文件：
![查询结果](https://img-blog.csdn.net/2018052918233443?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhaWR1XzM3OTY0MDcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
在域名解析的过程中仍然会优先查找hosts文件的内容。

### [域名解析时是tcp还是udp](https://www.cnblogs.com/wuyepeng/p/9835839.html)
DNS占用53号端口，同时使用TCP和UDP协议。
**DNS在区域传输的时候使用TCP协议，其他时候使用UDP协议。**
DNS**区域传输**的时候使用TCP协议：
1.辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。区域传送使用TCP而不是UDP，因为数据同步传送的数据量比一个请求应答的数据量要多得多。
2.TCP是一种可靠连接，保证了数据的准确性。
**域名解析**时使用UDP协议：
客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过三次握手，这样DNS服务器负载更低，响应更快。理论上说，客户端也可以指定向DNS服务器查询时用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包

### [域名发散和域名收敛](https://heptaluan.github.io/2017/12/01/HTTP/03/)
PC 时代为了突破浏览器的域名并发限制。有了域名发散。
浏览器有并发限制，是为了防止DDOS攻击。
域名收敛：就是将静态资源放在一个域名下。减少DNS解析的开销。
域名发散：是将静态资源放在多个子域名下，就可以多线程下载，提高并行度，使客户端加载静态资源更加迅速。
域名发散是pc端为了利用浏览器的多线程并行下载能力。而域名收敛多用与移动端，提高性能，因为dns解析是是从后向前迭代解析，如果域名过多性能会下降，增加DNS的解析开销。

---
## TCP
**TCP**：*Transmission Control Protocol 传输控制协议* 是一种面向连接（连接导向）的、可靠的、基于字节流的运输层（Transport layer）通信协议
**UDP**：*User Datagram Protocol 用户数据报协议* 是一种无需建立连接的即可以发送封装的IP数据包

### TCP和UDP的区别
TCP是面向链接的，而UDP是面向无连接的。
TCP仅支持单播传输，UDP 提供了单播，多播，广播的功能。
TCP的三次握手保证了连接的可靠性; UDP是无连接的、不可靠的一种数据传输协议，首先不可靠性体现在无连接上，通信都不需要建立连接，对接收到的数据也不发送确认信号，发送端不知道数据是否会正确接收。
UDP的头部开销比TCP的更小，数据传输速率更高，实时性更好。

### TCP三次握手
**第一次握手**：建立连接时，客户端会发送给服务器一个用于连接的同步报文SYN = 1 和一个随机生成的序号 seq = x。此时客户端进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。
**第二次握手**：当服务端接收到请求连接报文的时候，会发送一个同步确认报文，此报文 SYN = 1，并且 ACK = 1，同时服务端也会随机生成一个 seq = y，并将 ack 设置成 x + 1，回传给客户端。此时服务器进入SYN_RECV状态；
**第三次握手**：客户端收到服务器的SYN+ACK报文，向服务器发送确认包ACK(ack=k+1），此报文 ACK = 1，seq = x + 1, ack = y + 1。此报文发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。
![三次握手图例](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA1MTEwNDA1NjY2?x-oss-process=image/format,png)
*握手过程中传送的包里不包含数据，三次握手完毕后，客户端与服务器才正式开始传送数据。*

### TCP 四次挥手
**第一次挥手**：客户端打算断开连接，向服务器发送FIN报文(FIN标记位被设置为1，1表示为FIN，0表示不是)，FIN报文中会指定一个序列号，之后客户端进入FIN_WAIT_1状态。
也就是客户端发出连接释放报文段(FIN报文)，指定序列号seq = u，主动关闭TCP连接，等待服务器的确认。
**第二次挥手**：服务器收到连接释放报文段(FIN报文)后，就向客户端发送ACK应答报文，以客户端的FIN报文的序列号 seq+1 作为ACK应答报文段的确认序列号ack = seq+1 = u + 1。
接着服务器进入CLOSE_WAIT(等待关闭)状态，此时的TCP处于半关闭状态(下面会说什么是半关闭状态)，客户端到服务器的连接释放。客户端收到来自服务器的ACK应答报文段后，进入FIN_WAIT_2状态。
**第三次挥手**：服务器也打算断开连接，向客户端发送连接释放(FIN)报文段，之后服务器进入LASK_ACK(最后确认)状态，等待客户端的确认。
服务器的连接释放(FIN)报文段的FIN=1，ACK=1，序列号seq=m，确认序列号ack=u+1。
**第四次挥手**：客户端收到来自服务器的连接释放(FIN)报文段后，会向服务器发送一个ACK应答报文段，以连接释放(FIN)报文段的确认序号 ack 作为ACK应答报文段的序列号 seq，以连接释放(FIN)报文段的序列号 seq+1作为确认序号ack。
之后客户端进入TIME_WAIT(时间等待)状态，服务器收到ACK应答报文段后，服务器就进入CLOSE(关闭)状态，到此服务器的连接已经完成关闭。
*客户端处于TIME_WAIT状态时，此时的TCP还未释放掉，需要等待2MSL后，客户端才进入CLOSE状态。*
![四次挥手](https://imgconvert.csdnimg.cn/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTcwNjA2MDg0ODUxMjcy?x-oss-process=image/format,png)

### [为什么TCP连接需要三次握手，两次不可以吗，为什么](https://www.eet-china.com/mp/a75823.html)
**避免重复连接**
在网络环境比较复杂的情况，客户端可能会连续发送多次请求。如果只设计成两次握手的情况，服务端只能一直接收请求，然后返回请求信息，也不知道客户端是否请求成功。这些过期请求的话就会造成网络连接的混乱。所以设计成三次握手的情况，客户端在接收到服务端SEQ+1的返回消息之后，就会知道这个连接是历史连接，所以会发送报文给服务端，告诉服务端。

### TCP/IP 如何保证数据包传输的有序可靠？
对字节流分段并进行编号然后通过**ACK 回复**和**超时重发**这两个机制来保证。
1. 为了保证数据包的可靠传递，发送方必须把已发送的数据包保留在缓冲区；
2. 并为每个已发送的数据包启动一个超时定时器；
3. 如在定时器超时之前收到了对方发来的应答信息（可能是对本包的应答，也可以是对本包后续包的应答），则释放该数据包占用的缓冲区;
4. 否则，重传该数据包，直到收到应答或重传次数超过规定的最大次数为止。
5. 接收方收到数据包后，先进行CRC校验，如果正确则把数据交给上层协议，然后给发送方发送一个累计应答包，表明该数据已收到，如果接收方正好也有数据要发给发送方，应答包也可方在数据包中捎带过去。

### [TCP流式协议与粘包问题对策](https://cloud.tencent.com/developer/article/1848087)

### [粘包问题分析与对策](https://blog.csdn.net/wuxing26jiayou/article/details/79730987)
TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。
粘包出现原因
简单得说，在流传输中出现，UDP不会出现粘包，因为它有消息边界
粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包。
为了避免粘包现象，可采取以下几种措施：
1. 对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满；
2. 对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象；
3. 由接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包。分包多发。
以上提到的三种措施，都有其不足之处。

- 第一种编程设置方法虽然可以避免发送方引起的粘包，但它关闭了优化算法，降低了网络发送效率，影响应用程序的性能，一般不建议使用。
- 第二种方法只能减少出现粘包的可能性，但并不能完全避免粘包，当发送频率较高时，或由于网络突发可能使某个时间段数据包到达接收方较快，接收方还是有可能来不及接收，从而导致粘包。
- 第三种方法虽然避免了粘包，但应用程序的效率较低，对实时应用的场合不适合。
- 一种比较周全的对策是：**接收方创建一预处理线程，对接收到的数据包进行预处理，将粘连的包分开**。实验证明这种方法是高效可行的。

---
### [SSL/TLS](https://juejin.cn/post/6844904046063517704)
**定义**：TLS/SSL协议位于TCP/IP协议与各种应用层协议之间。SSL “安全套接层”标准化之后的名称改为 TLS，即“传输层安全协议”。

**SSL/TLS协议提供的服务主要有**：
1. 认证用户和服务器，确保数据发送到正确的客户机和服务器；
2. 加密数据以防止数据中途被窃取；
3. 维护数据的完整性，确保数据在传输过程中不被改变。

### 工作原理
客户端在使用 HTTPS 方式与 Web 服务器通信时有以下几个步骤：
（完成TCP握手之后）
1. 客户端使用 https url 访问服务器，则要求 web 服务器建立 ssl 链接。
2. web 服务器接收到客户端的请求之后，会将网站的证书（证书中包含了公钥），传输给客户端。
3. 客户端和 web 服务器端开始协商 SSL 链接的安全等级，也就是加密等级。
4. 客户端浏览器通过双方协商一致的安全等级，建立会话密钥，然后通过网站的公钥来加密会话密钥，并传送给网站。
5. web 服务器通过自己的私钥解密出会话密钥。
6. web 服务器通过会话密钥加密与客户端之间的通信。

**握手过程**：
![TLS握手过程](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/1/12/16f98d1f10d64aa7~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)
![详细图解](https://s5.51cto.com/oss/202201/06/cef7cd9b41ebf994927ceea2d1d80a4b.jpg)
1. "client hello"消息： 客户端通过发送"client hello"消息向服务器发起握手请求，该消息包含了客户端所支持的 TLS 版本和密码组合以供服务器进行选择，还有一个"client random"随机字符串。
2. "server hello"消息： 服务器发送"server hello"消息对客户端进行回应，该消息包含了数字证书，服务器选择的密码组合和"server random"随机字符串。
3. 验证： 客户端对服务器发来的证书进行验证，确保对方的合法身份，验证过程可以细化为以下几个步骤：
   - 检查数字签名
   - 验证证书链 (这个概念下面会进行说明)
   - 检查证书的有效期
   - 检查证书的撤回状态 (撤回代表证书已失效)
4. "premaster secret"字符串： 客户端向服务器发送另一个随机字符串"premaster secret (预主密钥)"，这个字符串是经过服务器的公钥加密过的，只有对应的私钥才能解密。
5. 使用私钥： 服务器使用私钥解密"premaster secret"。
6. 生成共享密钥： 客户端和服务器均使用 client random，server random 和 premaster secret，并通过相同的算法生成相同的共享密钥 KEY。
7. 客户端就绪： 客户端发送经过共享密钥 KEY加密过的"finished"信号。
8. 服务器就绪： 服务器发送经过共享密钥 KEY加密过的"finished"信号。
9. 达成安全通信： 握手完成，双方使用对称加密进行安全通信。

---
## [跨域，为什么JS会对跨域做出限制](https://segmentfault.com/a/1190000015597029)


---
## [前端安全：xss，csrf...](https://segmentfault.com/a/1190000038373771)
### XSS 跨站脚本攻击
**XSS 的注入点**：
- HTML 的节点内容或属性，存在读取可输入数据
- javascript 代码，存在由后台注入的变量或用户输入的信息
- 富文本

**XSS 危害**：
- 通过 document.cookie 盗取 cookie
- 使用 js 或 css 破坏页面正常的结构与样式
- 流量劫持（通过访问某段具有 window.location.href 定位到其他页面: `<script>window.location.href="www.baidu.com";</script>`）
- Dos 攻击：利用合理的客户端请求来占用过多的服务器资源，从而使合法用户无法得到服务器响应
- 利用 iframe、frame、XMLHttpRequest 或上述 Flash 等方式，以（被攻击）用户的身份执行一些管理动作，或执行一些一般的如发微博、加好友、发私信等操作
- 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动
- 偷取网站任意数据、用户资料等等

**类型**：
反射型（非持久）、存储型（持久）、DOM型

**防范方式**：
总体就是不能将用户的输入直接存到服务器，需要对一些数据进行特殊处理

- **设置 HttpOnly**
HttpOnly 是一个设置 cookie 是否可以被 javasript 脚本读取的属性，浏览器会禁止页面的 Javascript 访问带有 HttpOnly 属性的 Cookie。
*严格来说，这种方式不是防御 XSS，而是在用户被 XSS 攻击之后，不被获取 Cookie 数据。*

- **CSP 内容安全策略**
CSP(content security policy)，是一个额外的安全层，用于检测并削弱某些特定类型的攻击，包括跨站脚本 (XSS) 和数据注入攻击等。
CSP 可以通过 HTTP 头部（Content-Security-Policy）或<meta>元素配置页面的内容安全策略，以控制浏览器可以为该页面获取哪些资源。比如一个可以上传文件和显示图片页面，应该允许图片来自任何地方，但限制表单的 action 属性只可以赋值为指定的端点。
现在主流的浏览器内置了防范 XSS 的措施，开启 CSP，即开启白名单，可阻止白名单以外的资源加载和运行

- **输入检查**
对于用户的任何输入要进行编码、解码和过滤：
编码：不能对用户输入的内容都保持原样，对用户输入的数据进行字符实体编码转义
解码：原样显示内容的时候必须解码，不然显示不到内容了
过滤：把输入的一些不合法的东西都过滤掉，从而保证安全性。如移除用户上传的 DOM 属性，如 onerror，移除用户上传的 Style 节点、iframe、script 节点等
对用户输入所包含的特殊字符或标签进行编码或过滤，如 <，>，script，防止 XSS 攻击
```
function escHTML(str) {
  if (!str) return ''
  return str
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/x27/g, '&#039;')
    .replace(/x22/g, '&quto;')
}
```

- **输出检查**
用户的输入会存在问题，服务端的输出也会存在问题。一般来说，除富文本的输出外，在变量输出到 HTML 页面时，可以使用编码或转义的方式来防御 XSS 攻击。例如利用 sanitize-html 对输出内容进行有规则的过滤之后再输出到页面中。

- **输入内容长度控制**
对于不受信任的输入，都应该限定一个合理的长度。虽然无法完全防止 XSS 发生，但可以增加 XSS 攻击的难度。

- **验证码**
防止脚本冒充用户提交危险操作。


### CSRF(Cross Site Request Forgery) 跨站请求伪造
一种劫持受信任用户向服务器发送非预期请求的攻击方式。跨域指的是请求来源于其他网站，伪造指的是非用户自身的意愿。

**攻击方式**：
攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。
与 XSS 攻击不同的是：XSS 是攻击者直接对我们的网站 A 进行注入攻击，CSRF 是通过网站 B 对我们的网站 A 进行伪造请求。
例子：你登录购物网站 A 之后点击一个恶意链接 B，B 请求了网站 A 的下单接口，结果是在网站 A 的帐号生成一个订单。其背后的原理是：网站 B 通过表单、get 请求来伪造网站 A 的请求，这时候请求会带上网站 A 的 cookies，若登录态是保存在 cookies 中，则实现了伪造攻击。

跨站请求可以用各种方式：图片 URL、超链接、CORS、Form 提交等等。部分请求方式可以直接嵌入在第三方论坛、文章中。

**CSRF 危害**：
- 用户的登录态被盗用
- 冒充用户完成操作或修改数据

**CSRF 类型**：
GET类型、POST类型、链接类型

**防范方式**：
- 验证码
由于 CSRF 攻击伪造请求不会经过受攻击的网站，所以我们可以在网站加入验证码，这样必须通过验证码之后才能进行请求，有效的遏制了 CSRF 请求。
但是，这种方式不是万能的，并不是每个请求都加验证码，那样用户体验会非常不好，只能在部分请求添加，作为一种辅助的防御手段。

- 验证 Referer
在 HTTP 协议中，头部有个 Referer 字段，他记录了该 HTTP 请求的来源地址，在服务端设置该字段的检验，通过检查该字段，就可以知道该请求是否合法，不过请求头也容易伪造。

- cookie 设置 SameSite
设置 SameSite：设置 cookie 的 SameSite 值为 strict，这样只有同源网站的请求才会带上 cookie。这样 cookies 就不能被其他域名网站使用，达到了防御的目的。

- 添加 token 验证
浏览器请求服务器时，服务器返回一个 token，每个请求都需要同时带上 token 和 cookie 才会被认为是合法请求
这是一种相对成熟的解决方案。要抵御 CSRF，关键在于在请求中放入攻击者所不能伪造的信息，并且该信息不存在于 Cookie 之中。在服务端随机生成 token，在 HTTP 请求中以参数的形式加入这个 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。

- 更换登录态方案
因为 CSRF 本质是伪造请求携带了保存在 cookies 中的信息，所以对 session 机制的登录态比较不利，如果更换 JWT（JSON Web Token）方案，其 token 信息一般设置到 HTTP 头部的，所以可以防御 CSRF 攻击。

---
## Cookie、sessionStorage、localStorage 的区别
- 相同点：存储在客户端
- 不同点：
   - cookie数据大小不能超过4k；sessionStorage和localStorage的存储比cookie大得多，可以达到5M+
   - cookie设置的过期时间之前一直有效；localStorage永久存储，浏览器关闭后数据不丢失除非主动删除数据；sessionStorage数据在当前浏览器窗口关闭后自动删除
   - cookie的数据会自动的传递到服务器；sessionStorage和localStorage数据保存在本地

---

## [服务器如何知道你？](https://segmentfault.com/a/1190000017831088)
token, sessionId, cookies
- session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie
- cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。
- token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。
- jwt只是一个跨域认证的方案

---
## 浏览器缓存
### 介绍下304过程
- 客户端请求文件时，发现缓存中有这个文件，这个文件信息有Last Modified，那么在请求时会携带这个Last Modified当作请求中的If Modified Since，客户端会根据If Modified Since判断所对应的文件是否经过修改。无修改则返回304，指向缓存，无需下载。有修改则返回200，开始下载。
- 对于静态文件，例如：CSS、图片，服务器会自动完成 Last Modified 和 If Modified Since 的比较，完成缓存或者更新。但是对于动态页面，就是动态产生的页面，往往没有包含 Last Modified 信息，这样浏览器、网关等都不会做缓存，也就是在每次请求的时候都完成一个 200 的请求。
- 因此，对于动态页面做缓存加速，首先要在 Response 的 HTTP Header 中增加 Last Modified 定义，其次根据 Request 中的 If Modified Since 和被请求内容的更新时间来返回 200 或者 304 。虽然在返回 304 的时候已经做了一次数据库查询，但是可以避免接下来更多的数据库查询，并且没有返回页面内容而只是一个 HTTP Header，从而大大的降低带宽的消耗，对于用户的感觉也是提高。

### 浏览器查询缓存过程
- 浏览器请求资源时首先命中资源的Expires 和 Cache-Control，Expires 受限于本地时间，如果修改了本地时间，可能会造成缓存失效，可以通过Cache-control: max-age指定最大生命周期，状态仍然返回200，但不会请求数据，在浏览器中能明显看到from cache字样。（强制缓存）
- 强缓存失效，进入协商缓存阶段，首先验证ETag。ETag可以保证每一个资源是唯一的，资源变化都会导致ETag变化。服务器根据客户端上送的If-None-Match值来判断是否命中缓存。
- 协商缓存Last-Modify/If-Modify-Since阶段，客户端第一次请求资源时，服务服返回的header中会加上Last-Modify，Last-modify是一个时间标识该资源的最后修改时间。再次请求该资源时，request的请求头中会包含If-Modify-Since，该值为缓存之前返回的Last-Modify。服务器收到If-Modify-Since后，根据资源的最后修改时间判断是否命中缓存。（协商缓存）
![304过程](https://img-blog.csdnimg.cn/32a829cf0e0046adb6174b8414ba0705.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6KGM5Yqo5b6I6YeN6KaB5Yay5Yay5Yay,size_12,color_FFFFFF,t_70,g_se,x_16)

### [浏览器强缓存和协商缓存](https://cloud.tencent.com/developer/article/1947584)
**强制缓存**
强制缓存的情况主要有三种(暂不分析协商缓存过程)，如下：
1. 不存在该缓存结果和缓存标识，强制缓存失效，则直接向服务器发起请求（跟第一次发起请求一致）。
2. 存在该缓存结果和缓存标识，但该结果已失效，强制缓存失效，则使用协商缓存。
3. 存在该缓存结果和缓存标识，且该结果尚未失效，强制缓存生效，直接返回该结果

**协商缓存**
协商缓存主要有以下两种情况：
1. 协商缓存生效，返回304
2. 协商缓存失效，返回200和请求结果

---
## 说下进程、线程和协程
**进程**是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。
**线程**是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。
**协程**：英文Coroutines，是一种基于线程之上，但又比线程更加轻量级的存在，这种由程序员自己写程序来管理的轻量级线程叫做『用户空间线程』，具有对内核来说不可见的特性。
进程和线程的区别与联系
**区别**：
调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位；
并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行；
拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。
系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。但是进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个进程死掉就等于所有的线程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。
**联系**：
一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程；
资源分配给进程，同一进程的所有线程共享该进程的所有资源；
处理机分给线程，即真正在处理机上运行的是线程；
线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。

---
## 进程，线程，协程

进程——资源分配的最小单位，
线程——程序执行的最小单位。
协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。
协程与线程主要区别是它将不再被内核调度，而是交给了程序自己而线程是将自己交给内核调度。
**实际意义的区别**
（1）一个程序至少有一个进程,一个进程至少有一个线程。线程(Thread)是进程的一个实体，是CPU调度和分派的基本单位；
（2）进程拥有独立的内存单元，而多个线程共享内存。从而线程效率更高；
（3）进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮；
（4）进程切换时，耗费资源较大，效率要差一些；
（5）进程是系统资源分配的基本单位，线程是调度的基本单位。
**比较进程线程的优点**
（1）易于调度。
（2）提高并发性。通过线程可方便有效地实现并发性。进程可创建多个线程来执行同一程序的不同部分。
（3）开销少。创建线程比创建进程要快，所需开销很少。
（4）利于充分发挥多处理器的功能。
**相比进程线程的缺点**
（1）线程之间的同步和加锁控制比较麻烦
（2）一个线程的崩溃影响到整个程序的稳定性
（3）线程多了之后，线程本身的调度也是一个麻烦事儿，需要消耗较多的CPU
**通讯的区别**
（1）每个进程有自己的地址空间。两个进程中的地址即使值相同，实际指向的位置也不同。进程间通信一般通过操作系统的公共区进行。
同一进程中的线程因属同一地址空间，可直接通信。
（2）只有进程间需要通信,同一进程的线程share地址空间,没有通信的必要，但要做好同步/互斥mutex,保护共享的全局变量。线程拥有自己的栈。同步/互斥是原语primitives.  而进程间通信无论是信号，管道pipe还是共享内存都是由操作系统保证的，是系统调用.
（3）线程间通信：由于多线程共享地址空间和数据空间，所以多个线程间的通信是一个线程的数据可以直接提供给其他线程使用，而不必通过操作系统（也就是内核的调度）。进程间的通信则不同，它的数据空间的独立性决定了它的通信相对比较复杂，需要通过操作系统。以前进程间的通信只能是单机版的，现在操作系统都继承了基于套接字（socket）的进程间的通信机制。这样进程间的通信就不局限于单台计算机了，实现了网络通信。
**切换和调度**
线程上下文切换比进程上下文切换要快得多，在多线程程序下，进程不是一个可执行的实体

### 协程
协程是用户模式下的轻量级线程，最准确的名字应该叫用户空间线程（User Space Thread）
操作系统内核对协程一无所知，协程的调度完全有应用程序来控制，操作系统不管这部分的调度；
一个线程可以包含一个或多个协程，协程拥有自己的寄存器上下文和栈，协程调度切换时，将寄存器上下文和栈保存起来，在切换回来时恢复先前保运的寄存上下文和栈。
协程的优势如下：
节省内存，每个线程需要分配一段栈内存，以及内核里的一些资源
节省分配线程的开销（创建和销毁线程要各做一次 syscall）
节省大量线程切换带来的开销
与 NIO 配合实现非阻塞的编程，提高系统的吞吐

### 进程间的通讯方式
（1）管道：半双工；数据只能单向流动，只能用于具有亲缘关系的进程之间，即用于父子、兄弟之间。
（2）命名管道（FIFO）：半双工，允许无亲缘关系的进程
（3）消息队列：消息链表存于内核，每个消息队列由消息队列标识符标识；于管道不同的是，消息队列存放在内核中，只有在内核重启时才能删除一个消息队列；消息队列的大小受限制。
（4）信号量（semophore）：信号量是一个计数器，可以用来控制多个进程对于共享资源的访问。作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源，常用来处理临界资源的访问同步问题。
临界资源：为某一时刻只能由一个进程或线程操作的资源。
（5）共享内存：就是映射一段能被其他进程所访问的内存，这段内存由一个进程创建，但可以多个进程同时访问，可以说是最有用的进程间通信方式，也是最快的IPC形式。 常与其他通讯机制（信号量）配合使用。
（6）套接字：也可用于不同机器之间。
（7）信号（Signal）：比较复杂，用于通知接收进程某个事件已经发生

### 进程的状态
1. 创建状态：程由创建而产生。创建进程是一个非常复杂的过程，一般需要通过多个步骤才能完成：如首先由进程申请一个空白的进程控制块(PCB)，并向PCB中填写用于控制和管理进程的信息；然后为该进程分配运行时所必须的资源；最后，把该进程转入就绪状态并插入到就绪队列中。
2. 就绪状态：这是指进程已经准备好运行的状态，即进程已分配到除CPU以外所有的必要资源后，只要再获得CPU，便可立即执行。如果系统中有许多处于就绪状态的进程，通常将它们按照一定的策略排成一个队列，该队列称为就绪队列。有执行资格，没有执行权的进程。
3. 运行状态：这里指进程已经获取CPU，其进程处于正在执行的状态。对任何一个时刻而言，在单处理机的系统中，只有一个进程处于执行状态而在多处理机系统中，有多个进程处于执行状态。既有执行资格，又有执行权的进程。
4. 阻塞状态：这里是指正在执行的进程由于发生某事件（如I/O请求、申请缓冲区失败等）暂时无法继续执行的状态，即进程执行受到阻塞。此时引起进程调度，操作系统把处理机分配给另外一个就绪的进程，而让受阻的进程处于暂停的状态，一般将这个暂停状态称为阻塞状态
5. 终止状态：进程的终止也要通过两个步骤：首先，是等待操作系统进行善后处理，最后将其PCB清零，并将PCB空间返还给系统。当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入终止状态。进入终止态的进程以后不能在再执行，但是操作系统中任然保留了一个记录，其中保存状态码和一些计时统计数据，供其他进程进行收集。一旦其他进程完成了对其信息的提取之后，操作系统将删除其进程，即将其PCB清零，并将该空白的PCB返回给系统。

### 线程共享的和独有的内容
线程独有的内容：
线程上下文  包括：线程ID 、栈、栈指针、PC（程序计数器）、通用目的寄存器、条件码、 错误返回码、 线程的信号屏蔽码、 线程的优先级
线程共享的内容：
线程共享的环境包括：进程代码段、进程的公有数据、进程打开的文件描述符、信号的处理器、进程的当前目录、进程用户 ID 与进程组 ID 等

### 线程同步的方式
线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。
锁机制：包括互斥锁、条件变量、读写锁
（1）临界区：当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止。
（2） 互斥量（Mutex）： 提供了以排他方式防止数据结构被并发修改的方法， 互斥对象和临界区对象非常相似，只是其允许在进程间使用，也可在线程间使用，而临界区只限制与同一进程的各个线程之间使用。
（3）条件变量：以原子的方式阻塞进程，直到某个特定条件为真为止，一个线程被挂起，直到某件事件发生。
条件变量始终与互斥锁一起使用。
（4）信号量（semaphore）：当需要一个计数器来限制可以使用某共享资源的线程数目时，可以使用“信号量”对象。CSemaphore类对象保存了对当前访问某一个指定资源的线程的计数值，该计数值是当前还可以使用该资源的线程数目。如果这个计数达到了零，则所有对这个CSemaphore类对象所控制的资源的访问尝试都被放入到一个队列中等待，直到超时或计数值不为零为止。 mutex是semaphore的一种特殊情况（n=1时）。也就是说，完全可以用后者替代前者。但是，因为mutex较为简单，且效率高，所以在必须保证资源独占的情况下，还是采用这种设计。
（5）信号：类似进程间的信号处理
（6）事件：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。
（7）套接字：可用于两个机器之间

### 多线程的锁机制
互斥量（Mutex） 互斥量是实现最简单的锁类型，因此有一些教科书一般以互斥量为例对锁原语进行描述。互斥量的释放并不仅仅依赖于释放操作，还可以引入一个定时器属性。如果在释放操作执行前发生定时器超时，则互斥量也会释放代码块或共享存储区供其他线程访问。当有异常发生时，可使用try-finally语句来确保互斥量被释放。定时器状态或try-finally语句的使用可以避免产生死锁。

递归锁（Recursive Lock） 递归锁是指可以被当前持有该锁的线程重复获取，而不会导致该线程产生死锁的锁类型。对递归锁而言，只有在当前持有线程的获取锁操作都有一个释放操作与之对应时，其他线程才可以获取该锁。因此，在使用递归锁时，必须要用足够的释放锁操作来平衡获取锁操作，实现这一目标的最佳方式是在单入口单出口代码块的两头一一对应地使用获取、释放操作，做法和在普通锁中一样。递归锁在递归函数中最有用。但是，总的来说，递归锁比非递归锁速度要慢。需要注意的是：调用线程获得几次递归锁必须释放几次递归锁。

读写锁（Read-Write lock） 读写锁又称为共享独占锁（shared-exclusive lock）、多读单写锁（multiple-read/single-write lock）或者非互斥信号量（non-mutual exclusion semaphore）。读写锁允许多个线程同时进行读访问，但是在某一时刻却最多只能由一个线程执行写操作。对于多个线程需要同时读共享数据却并不一定进行写操作的应用来说，读写锁是一种高效的同步机制。对于较长的共享数据，只为其设置一个读写锁会导致较长的访问时间，最好将其划分为多个小段并设置多个读写锁以进行同步。

旋转锁（Spin Lock） 旋转锁是一种非阻塞锁，由某个线程独占。采用旋转锁时，等待线程并不静态地阻塞在同步点，而是必须“旋转”，不断尝试直到最终获得该锁。旋转锁多用于多处理器系统中。这是因为，如果在单核处理器中采用旋转锁，当一个线程正在“旋转”时，将没有执行资源可供另一释放锁的线程使用。旋转锁适合于任何锁持有时间少于将一个线程阻塞和唤醒所需时间的场合。线程控制的变更，包括线程上下文的切换和线程数据结构的更新，可能比旋转锁需要更多的指令周期。旋转锁的持有时间应该限制在线程上下文切换时间的50%到100%之间（Kleiman，1996年）。在线程调用其他子系统时，线程不应持有旋转锁。对旋转锁的不当使用可能会导致线程饿死，因此需谨慎使用这种锁机制。旋转锁导致的饿死问题可使用排队技术来解决，即每个等待线程按照先进先出的顺序或者队列结构在一个独立的局部标识上进行旋转

### 进程间通讯方式的区别
共享内存和消息队列，FIFO，管道传递消息的区别：
后者，消息队列，FIFO，管道的消息传递方式一般为
1：服务器得到输入
2：通过管道，消息队列写入数据，通常需要从进程拷贝到内核。
3：客户从内核拷贝到进程
4：然后再从进程中拷贝到输出文件
上述过程通常要经过4次拷贝，才能完成文件的传递。
而共享内存只需要
1:从输入文件到共享内存区
2:从共享内存区输出到文件
上述过程不涉及到内核的拷贝，所以花的时间较少。

### 多线程编程（线程池），如何确定线程的个数
首先确定应用是CPU密集型 （例如分词，加密等），还是耗时io（ 网络，文件操作等）
CPU密集型：最佳线程数等于cpu核心数或稍微小于cpu核心数  Cpu的核数 = 线程数就行，一般我们会设置 Cpu核数+1 防止由于其他因素导致线程阻塞等。
耗时io型：最佳线程数一般会大于cpu核心数很多倍。。一般是io设备延时除以cpu处理延时，得到一个倍数，我的经验数值是20--50倍*cpu核心数。
多核Cpu 最佳线程数 =CPU 核数 * [ 1 +（I/O 耗时 / Cpu 耗时）
最佳线程数量也与机器配置（内存，磁盘速度）有关，如果cpu，内存，磁盘任何一个达到顶点，就需要适当减少线程数。

默认情况下，一个线程的栈要预留1M的内存空间,而一个进程中可用的内存空间只有2G，所以理论上一个进程中最多可以开2048个线程,但是内存当然不可能完全拿来作线程的栈，所以实际数目要比这个值要小。

### 使用多线程的原因
1. 防止界面卡死.
提高用户的用户体验
对单核CPU，对客户端软件，采用多线程，主要是 创建多线程将一些计算放在后台执行，而不影响用户交互操作。（用户界面 & 其他计算 并行进行）提高用户的操作性能！
2. 耗时的操作(io,网络io等)使用线程，提高cpu使用率..
I/O操作不仅包括了直接的文件、网络的读写，还包括数据库操作、Web Service、HttpRequest以及.net Remoting等跨进程的调用。
要是不使用多线程,你回发现cpu使用率很空闲.
3. 多CPU(核心)中，使用线程提高CPU利用率
使多CPU系统更加有效
操作系统会保证当线程数不大于CPU数目时，不同的线程运行于不同的CPU上。
要是不使用多线程,你回发现仅仅一个cpu很忙碌的,其他cpu使用率很空闲.
4. 不适用多线程的情况
a.你的代码是cpu密集型,在单核cpu上..
b.单核cpu上,线程的使用（滥用）会给系统带来上下文切换的额外负担。并且线程间的共享变量可能造成死锁的出现。
c.当需要执行I/O操作时，使用异步操作常常比使用线程+同步I/O操作更合适。
对于耗时io型，一个简单的算法：：最佳线程数==单个线程的黄色时间块长度（空闲） / 绿色时间块长度（繁忙） * cpu核心数